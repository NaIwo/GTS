device: cpu # {cpu, gpu}
dataset:
  dataset-name: lap14 # {lap14, res14, res15, res16}
  batch-size: 4
  shuffle-seed: null
sentence:
  max-length: 100
task:
  type: triplet  # pair or triplet
  class-number:
    triplet: 6
    pair: 4
model:
  type: bert # {bert, cnn, bilstm}
  inference: 2
  epochs: 100
  learning-rate: 0.001
  bert:
    source: bert-base-uncased
encoder:
  type: bert  # {bert, glove-fasttext, indexer}
  bert:
    source: bert-base-uncased
    embedding-dimension: 768
  # All encoder files should be kept in datasets/datasets/embeddings_data directory
  glove-fasttext:
    fasttext-model: model_lap14.bin # <-- pay attention to that
    glove-file: gen.vec.npy
    indexer-path: word_idx.json
    embedding-dimension: 400
  indexer:
    fasttext-file: lap14_emb.vec.npy # <-- pay attention to that
    glove-file: gen.vec.npy
    indexer-path: word_idx.json
    embedding-dimension: 400