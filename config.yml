general:
  device: cpu # {cpu, gpu}
  logging-level: INFO
dataset:
  dataset-name: lap14 # {lap14, res14, res15, res16}
  batch-size: 4
  shuffle-seed: null
  valid-sample-ratio: 1.0
sentence:
  max-length: 100
task:
  type: triplet  # pair or triplet
  class-number:
    triplet: 6
    pair: 4
model:
  type: bilstm # {bert, cnn, bilstm}
  training: true
  bert:
    epochs: 100
    learning-rate: 0.00001
    inference: 1
    source: bert-base-uncased
  cnn:
    epochs: 600
    learning-rate: 0.001
    inference: 2
    attention-dimension: 50
  bilstm:
    epochs: 600
    learning-rate: 0.001
    inference: 3
    attention-dimension: 50
encoder:
  type: indexer  # {bert, glove-fasttext, indexer}
  bert:
    source: bert-base-uncased
    embedding-dimension: 768
  # All encoder files should be kept in datasets/datasets/embeddings_data directory
  glove-fasttext:
    fasttext-model: model_lap14.bin # <-- pay attention to that
    glove-file: gen.vec.npy
    indexer-path: word_idx.json
    embedding-dimension: 400
  indexer:
    fasttext-file: lap14_emb.vec.npy # <-- pay attention to that
    glove-file: gen.vec.npy
    indexer-path: word_idx.json
    embedding-dimension: 400